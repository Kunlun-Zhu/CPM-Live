
# CPM-Live Training Log (June, 20)

Time: June, 20 2022 16:00

Recorder: @zh-zheng

## Loss
- Begin: 2.48
- End: 2.46  
	
## Completed Data
- $\approx$ 223.67GB

## Average Grad Norm
- 0.79

## Progress
- 24.02%

## Comment

After the restart, our model worked fine and was trained steadily for a whole day. We suspect that the CUDA OOM issue yesterday may be related to GPU memory fragmentation in PyTorch.

It's also worth mentioning that our WeChat official account (OpenBMB) posted an [article](https://mp.weixin.qq.com/s/ugvIrUGVSqSXnW-2A3bLjA) today about the technical principles of the [BMTrain](https://github.com/OpenBMB/BMTrain) toolkit, which is used to train CPM-Live efficiently. Read it if you are interested and any discussions are welcomed!
