# CPM-Live训练计划书

## 一、计划总览
CPM-Live直播训练是以CPM系列模型为架构基础的开源大模型直播训练，训练过程将采用持续学习方式并实时直播训练进展。和现有的开源大模型以及相关直播相比，CPM-Live具有以下特点：

- **持续学习**。现有开源大模型在训练完成后即告一段落，CPM-Live基于持续学习方法，将于未来较长时间内持续进行训练与完善。具体来说，CPM-Live的训练将分为若干阶段，我们将以训练10B大模型为起点，提供中英文支持以及结构化输入输出能力。在后续训练中，CPM-Live模型规模将不断扩大，数据将不断增多，能力将不断完善，语言将不断丰富。

- **开放民主**。CPM-Live倡导开源共建，CPM-Live训练过程希望积极征求开源社区的意见建议。在CPM-Live训练过程中，社区用户可对CPM-Live模型包括但不限于**模型特性、训练方式、使用数据**等方面提出倡议，其中成熟的倡议将有可能集成于最终模型。此外，CPM-Live倡导开放，训练结束后将提供相关模型参数下载，并采用包括允许商业化在内的开放模型使用协议。

- **高效计算**。CPM-Live训练、压缩、推理过程将基于OpenBMB开源社区系列工具包。通过大模型训练“发动机”**BMTrain**，我们可以在小规模的集群中训练百亿以上规模的超大模型，这大幅降低了模型训练的成本，也使我们的训练更加低碳和高效。使用大模型“瘦身”工具库**BMCook**和高效推理工具包**BMInf**，普通用户可以在消费级显卡上运行大模型，从而更加便捷地体验大模型的魅力。

## 二、CPM-Live模型
### （一）模型架构
CPM-Live的模型架构与主要设置如下：

- **统一编码器框架**：采用pre-norm的encoder架构，通过调整attention的mask矩阵来切换模型进行编码、解码、编码解码。选用pre-norm可确保训练相对稳定。

<div align="center">
<img src="./pics/framework.png" width="600px" />
</div>

- **模块化设计：我们的模型采用模块化设计，形成基于提示模板的多段组合形式**（prompt-based multi-segment combination）。prompt用以控制模型的功能模式。segment则用以控制模型的编码/解码模式。例如我们可以设计一个segment，通过MLM进行预训练；设计另一个segment，通过LM进行预训练；两个segment拼接组合，可以进行摘要或者改写的预训练。在具体操作上，每个segment内输入为token embedding和segment embedding的组合，采样相对位置编码。跨segment会额外设计位置编码，来促进各个segment之间的信息交互。

	模块化设计的好处是易于增加、修改模块，进行持续学习和功能更新。复杂的任务模型也可以拆解成若干个简单的子模块拼接，降低设计模型难度。

- **共享embedding**：CPM-Live输入embedding及输出embedding会共享参数，这点与BERT、GPT、T5一致，与T5-1.1、mT5不一致。我们的实验表明共享输入输出的embedding参数会极大增强训练稳定程度，而不共享embedding参数易于导致训练过程出现NaN。
- **无bias**：我们的模型中，各类线性变换及layer norm均不设置bias。一方面源于不设置bias的模型训练稳定性会更强，另一方面也是不设置bias的模型在计算速度及显存消耗上要更占优。
- **动态词表**：对于词表，初始阶段我们将提供大小为50000的中文词表，在后续训练过程中会结合新数据情况进行动态变动。
- **参数初始化**：embedding ∼ N (0, $\frac{1}{\sqrt{d}}$),  线性层参数 ∼ N (0, 1)。
- **维度归一化**：Attention层及FFN层中的矩阵运算均要除以√ d。
- **Sequence length**：初始512，后续增长为1024，直至2048。
- **Batch size**: 初始1024，后续增长到2048。